Designing a new evaluation framework
====



#Important questions

Where does visualization fit in a data science evaluation? __Data science__ involves techniques for _analyzing_ and _extracting knowledge_ from data.

The purpose of information visualization is to function as a _problem solving tool_. Data visualization relies on __context__. In other words, solving a specific problem in a particular domain. Many previous methods of data visualization often measure the utility of a visualization in terms of effectively users can accomplish their context-specific tasks.

For example, the same data can be represented many different ways. The effectiveness of a visualization is tied into _which_ representation strategy is chosen to fit the task. 

Can we tease measurement of the visualization from the context of use? Certainly specific technologies can be measured (such as visualization for the browser, or for mobile devices).

Some questions needed to be answered:

__Abstract__
- Should a prospective visualization task emulate real world application/use case?
- What are the problems the datasets should be solving for a visualization task?
- Should we model off of recent visualization evaluation work. 

__Logistical__
- Should an entire software package be tested, despite possibly involving tasks not directly involved with visualization?
- Should clean or dirty data should be used for visualization?

#Resources

- [An Introduction and Guide to Evaluation of Visualization Techniques Through User Studies](http://link.springer.com/chapter/10.1007/978-1-4614-7485-2_11)